{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "%matplotlib inline\n",
    "# from tomkin import detect_rpeak\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from outlier_calculation import Quality,compute_outlier_ecg\n",
    "# from hrvanalysis import remove_ectopic_beats\n",
    "from joblib import Parallel,delayed\n",
    "# from data_quality import compute_quality,ECGQualityCalculation_BLE,ECGQualityCalculation\n",
    "from joblib import delayed,Parallel\n",
    "# from decode import Preprc\n",
    "from scipy import signal\n",
    "import shutil\n",
    "import math\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.patches as pat\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy import signal\n",
    "%matplotlib inline\n",
    "from scipy.stats import skew,kurtosis\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.stats import iqr\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def complementary_filter(accel_gyro, fq=25):\n",
    "    ts = accel_gyro[:,0]\n",
    "    acc_x = accel_gyro[:,5]\n",
    "    acc_y = accel_gyro[:,6]\n",
    "    acc_z = accel_gyro[:,7]\n",
    "    gyr_x = accel_gyro[:,8]\n",
    "    gyr_y = accel_gyro[:,9]\n",
    "    gyr_z = accel_gyro[:,10]\n",
    "\n",
    "    dt = 1.0 / fq  # 1/16.0;\n",
    "    M_PI = math.pi\n",
    "    hpf = 0.85\n",
    "    lpf = 0.15\n",
    "\n",
    "    thetaX_acc = [0] * len(acc_x)  # math.atan2(-acc_z,acc_y)*180/M_PI;\n",
    "    thetaY_acc = [0] * len(acc_x)  # math.atan2(acc_x,acc_z)*180/M_PI;\n",
    "    thetaZ_acc = [0] * len(acc_x)  # math.atan2(acc_y,acc_x)*180/M_PI;\n",
    "\n",
    "    thetaX = [0] * len(gyr_x)\n",
    "    thetaY = [0] * len(gyr_y)\n",
    "    thetaZ = [0] * len(gyr_z)\n",
    "\n",
    "    for index in range(len(gyr_x)):\n",
    "        thetaX_acc[index] = math.atan2(-acc_z[index], acc_y[index]) * 180 / M_PI\n",
    "        thetaY_acc[index] = math.atan2(acc_x[index], acc_z[index]) * 180 / M_PI\n",
    "        thetaZ_acc[index] = math.atan2(acc_y[index], acc_x[index]) * 180 / M_PI\n",
    "\n",
    "        if index == 0:\n",
    "            thetaX[index] = hpf * thetaX[index] * dt + lpf * thetaX_acc[index]\n",
    "            thetaY[index] = hpf * thetaY[index] * dt + lpf * thetaY_acc[index]\n",
    "            thetaZ[index] = hpf * thetaZ[index] * dt + lpf * thetaZ_acc[index]\n",
    "        else:\n",
    "            thetaX[index] = hpf * (thetaX[index - 1] + gyr_x[index] * dt) + lpf * thetaX_acc[index]\n",
    "            thetaY[index] = hpf * (thetaY[index - 1] + gyr_y[index] * dt) + lpf * thetaY_acc[index]\n",
    "            thetaZ[index] = hpf * (thetaZ[index - 1] + gyr_z[index] * dt) + lpf * thetaZ_acc[index]\n",
    "\n",
    "    roll_pitch_yaw = np.zeros((len(ts),7))\n",
    "    roll_pitch_yaw[:,0] = ts\n",
    "    roll_pitch_yaw[:,1:4] =  accel_gyro[:,1:4]\n",
    "    roll_pitch_yaw[:,4] = thetaX\n",
    "    roll_pitch_yaw[:,5] = thetaY\n",
    "    roll_pitch_yaw[:,6] = thetaZ\n",
    "    return roll_pitch_yaw\n",
    "\n",
    "def get_metric(window):\n",
    "    f,pxx = signal.welch(window[:,1],fs=25,nperseg=len(window[:,1]),nfft=1000)\n",
    "    pxx = np.abs(pxx)\n",
    "    pxx = pxx/max(pxx)\n",
    "    return np.array([skew(window[:,1]),kurtosis(window[:,1]),np.trapz(pxx[np.where((f>=.8)&(f<=2.5))[0]])/np.trapz(pxx),\n",
    "                len(np.where(np.diff(np.signbit(window[:,1])))[0])/len(window[:,1])]).reshape(-1,4)\n",
    "\n",
    "def get_classified_data(ppg_data,final_path,r,clf,ecg_rr):\n",
    "    print(ppg_data.shape)\n",
    "    roll_pitch_yaw = complementary_filter(ppg_data)\n",
    "    print(roll_pitch_yaw.shape)\n",
    "    final_ppg_data = np.zeros((ppg_data.shape[0],20))\n",
    "    final_ppg_data[:,14:17] = roll_pitch_yaw[:,4:]\n",
    "    print(roll_pitch_yaw.shape,'again')\n",
    "    index_col = []\n",
    "    chnls = [np.zeros((0,4)),np.zeros((0,4)),np.zeros((0,4))]\n",
    "    for i in range(30,len(ppg_data[:,0])-30,1):\n",
    "        t = ppg_data[i,0]\n",
    "        final_ppg_data[i,:11] = ppg_data[i,:]\n",
    "        ppg_window = ppg_data[i-30:i+30,:]\n",
    "        temp_window = RobustScaler().fit_transform(ppg_window[:,2:5])\n",
    "        final_ppg_data[i,17:] = temp_window[ppg_window[:,0]==t,:]\n",
    "        index_col.append(i)\n",
    "        for k in range(2,5,1):\n",
    "            window = np.concatenate([ppg_window[:,0].reshape(-1,1),signal.detrend(temp_window[:,k-2]).reshape(-1,1)],\n",
    "                                    axis=1)\n",
    "            f = get_metric(window)\n",
    "            chnls[k-2] = np.concatenate((chnls[k-2],f))\n",
    "        if i%1000==0:\n",
    "            print(i)\n",
    "    index_col = np.array(index_col)\n",
    "    for i in range(2,5,1):\n",
    "        final_ppg_data[index_col,11+k-2] = clf.predict_proba(chnls[k-2])[:,1]\n",
    "    final_ppg_data = final_ppg_data[final_ppg_data[:,0]>0,:]\n",
    "    print(final_ppg_data.shape,'final')\n",
    "    return final_ppg_data,final_path,r,ecg_rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pickle.load(open('./data_saved/temp_data_ecg.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "final_data1 = []\n",
    "for a in final_data:\n",
    "    if len(a[0])<10000:\n",
    "        continue\n",
    "    a[0][:,5:8] = a[0][:,5:8]*2/16384\n",
    "    a[0][:,8:] = 500.0 * a[0][:,8:] / 32768\n",
    "    split_data = np.array_split(a[0],10)\n",
    "    for b in split_data:\n",
    "        final_data1.append([b,a[1],a[2]])\n",
    "print(len(final_data))\n",
    "final_data = final_data1\n",
    "print(len(final_data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   1 tasks      | elapsed: 112.5min\n"
     ]
    }
   ],
   "source": [
    "clf = pickle.load(open('./temp/classifier.p','rb'))\n",
    "from joblib import Parallel,delayed\n",
    "# final_data2 = [get_classified_data(a[0],a[1],a[2],clf,a[3]) for a in final_data]\n",
    "final_data2 = Parallel(n_jobs=20,verbose=2)(delayed(get_classified_data)(a[0],a[1],a[2],clf,a[3]) for a in final_data)\n",
    "pickle.dump(final_data2,open('./data_saved/data_all_jhu_processed.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "final_data = pickle.load(open('./data_saved/data_all_mperf_processed.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(final_data[0][0][7000:8000,14:17])\n",
    "plt.show()\n",
    "plt.plot(final_data[0][0][7000:8000,17:])\n",
    "plt.show()\n",
    "plt.plot(final_data[0][0][7000:8000,11:14])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump([window_col,label_col],open('./data_saved/windows_all_inertail.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(final_data,open('./data_saved/data_all_mperf.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = np.array([np.array(a) for a in label_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [np.var(np.sum(np.abs(a[:,5:8]),axis=1)) for a in window_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.zeros((label_col.shape[0],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature[:,1] = x\n",
    "feature[:,0] = label_col[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,np.max(label_col,axis=1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "df = pd.DataFrame(feature,columns=['x','y'])\n",
    "sns.jointplot(x='x', y='y', kind=\"kde\", color=\"k\",data=df)\n",
    "plt.ylim([0,.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
